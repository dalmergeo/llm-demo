{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caed1fac-6883-4453-b1d4-57c5f748f320",
   "metadata": {},
   "source": [
    "# Leveraging LLMs in Code: An Interactive Exploration\n",
    "\n",
    "Welcome to our Lunch & Learn session! Today, we'll explore how to harness the power of Large Language Models (LLMs) within our code. We'll cover:\n",
    "\n",
    "- **Basics:** Understanding LLMs and effective prompt engineering.\n",
    "- **API Calling:** How to interact with LLMs via API requests.\n",
    "- **Retrieval-Augmented Generation (RAG):** Combining external data with LLM responses.\n",
    "- **Function Calling:** Integrating LLMs with your code logic through function calls.\n",
    "- **Miscellaneous:** Best practices, debugging, security, and real-world applications.\n",
    "\n",
    "Let's dive in and explore the possibilities together!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90c680f-1a31-4d5b-93d8-64abb1624cb8",
   "metadata": {},
   "source": [
    "# 1. Basics\n",
    "\n",
    "In this section, we'll cover the foundational concepts necessary for working with LLMs.\n",
    "\n",
    "## What are LLMs?\n",
    "- **Definition:** Large Language Models are AI systems that understand and generate human-like text.\n",
    "- **Examples:** Chatbots, code assistants, content generators, etc.\n",
    "- **Key Points:** \n",
    "  - Trained on massive datasets\n",
    "  - Use deep learning techniques\n",
    "  - Adapt to various contexts and tasks\n",
    "\n",
    "## Prompt Engineering\n",
    "- **Importance:** The quality of your input prompt greatly influences the output.\n",
    "- **Tips:**\n",
    "  - Be clear and specific.\n",
    "  - Experiment with different phrasings.\n",
    "  - Use context to guide the model.\n",
    "- **Example:**\n",
    "  - Poor prompt: \"Tell me about Python.\"\n",
    "  - Better prompt: \"Can you provide a brief overview of Python programming, including its key features and use cases?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0eb62b-0c47-4ff6-9fbe-92b40bbb5c92",
   "metadata": {},
   "source": [
    "# 3. Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "Enhance LLM outputs by integrating external data retrieval.\n",
    "\n",
    "## What is RAG?\n",
    "- **Concept:** Combine LLM capabilities with a retrieval system (like a vector database or document store).\n",
    "- **Workflow:**\n",
    "  1. Retrieve relevant data based on a query.\n",
    "  2. Feed retrieved context into the LLM.\n",
    "  3. Generate a more informed and accurate response.\n",
    "\n",
    "## Example Use Case\n",
    "- **Scenario:** Answering customer queries by pulling information from internal documents.\n",
    "- **Benefits:** \n",
    "  - More accurate responses.\n",
    "  - Context-aware generation.\n",
    "\n",
    "## Example Code Outline (Pseudo-code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f29237f-d6da-451d-9585-1db3dbfc5a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment loaded. OpenAI and Merge API keys are set. OpenAI client created.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import faiss\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from .env\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MERGE_API_KEY = os.getenv(\"MERGE_API_KEY\")\n",
    "MERGE_ACCOUNT_TOKEN = os.getenv(\"MERGE_ACCOUNT_TOKEN\")\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "print(\"Environment loaded. OpenAI and Merge API keys are set. OpenAI client created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4c67a91-fc35-4f18-bca4-4b7284c68259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 20 documents from Merge API.\n",
      "Sample document:\n",
      " Name: Samantha Harris\n",
      "Relationship: SPOUSE\n",
      "Gender: FEMALE\n"
     ]
    }
   ],
   "source": [
    "def fetch_hr_data():\n",
    "    # Replace the URL with the actual endpoint from Merge that returns HR data\n",
    "    url = \"https://api.merge.dev/api/hris/v1/dependents\"  \n",
    "    headers = {\"Authorization\": f\"Bearer {MERGE_API_KEY}\", \"X-Account-Token\": MERGE_ACCOUNT_TOKEN}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()  # Raises an error if the API call fails\n",
    "    data = response.json()\n",
    "    \n",
    "    # Assume data contains a list of dependents records in the \"results\" key\n",
    "    documents = []\n",
    "    for item in data.get(\"results\", []):\n",
    "        # Build a simple text snippet for each employee record:\n",
    "        doc = (\n",
    "            f\"Name: {item.get('first_name', '')} {item.get('last_name', '')}\\n\"\n",
    "            f\"Relationship: {item.get('relationship', '')}\\n\"\n",
    "            f\"Gender: {item.get('gender', '')}\"\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    return documents\n",
    "\n",
    "# Fetch and inspect the documents\n",
    "documents = fetch_hr_data()\n",
    "print(f\"Fetched {len(documents)} documents from Merge API.\")\n",
    "print(\"Sample document:\\n\", documents[0] if documents else \"No data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe33432b-2b82-4d70-bd2d-96c844dee917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed embeddings shape: (20, 1536)\n"
     ]
    }
   ],
   "source": [
    "def compute_embeddings(docs):\n",
    "    embeddings = []\n",
    "    for doc in docs:\n",
    "        res = client.embeddings.create(\n",
    "            input=doc,\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )\n",
    "        embedding = res.data[0].embedding\n",
    "        embeddings.append(embedding)\n",
    "    return np.array(embeddings).astype('float32')\n",
    "\n",
    "# Compute embeddings for our HR documents\n",
    "embeddings = compute_embeddings(documents)\n",
    "print(\"Computed embeddings shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94844859-b504-4d41-8a05-3075c52f09b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built with 20 documents.\n"
     ]
    }
   ],
   "source": [
    "# Determine the dimensionality of our embeddings\n",
    "dimension = embeddings.shape[1]\n",
    "# Create a FAISS index (L2 distance based)\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "# Add our embeddings to the index\n",
    "index.add(embeddings)\n",
    "print(\"FAISS index built with\", index.ntotal, \"documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b330fff0-45b0-406f-95b9-ce9fe4ab592d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matching document indices: [17  9  5  8 18 10 16 12 15 14 19  7]\n",
      "\n",
      "Top matching documents:\n",
      "\n",
      "--- Document ---\n",
      "Name: Benjamin Adams\n",
      "Relationship: CHILD\n",
      "Gender: MALE\n",
      "\n",
      "--- Document ---\n",
      "Name: Mason Vance\n",
      "Relationship: CHILD\n",
      "Gender: MALE\n",
      "\n",
      "--- Document ---\n",
      "Name: Brock Walsh\n",
      "Relationship: CHILD\n",
      "Gender: MALE\n",
      "\n",
      "--- Document ---\n",
      "Name: Mark Vance\n",
      "Relationship: CHILD\n",
      "Gender: MALE\n",
      "\n",
      "--- Document ---\n",
      "Name: Fred Abbott\n",
      "Relationship: CHILD\n",
      "Gender: MALE\n",
      "\n",
      "--- Document ---\n",
      "Name: Matthew Vance\n",
      "Relationship: CHILD\n",
      "Gender: MALE\n",
      "\n",
      "--- Document ---\n",
      "Name: Michael Adams\n",
      "Relationship: SPOUSE\n",
      "Gender: MALE\n",
      "\n",
      "--- Document ---\n",
      "Name: Jonathan Sterling\n",
      "Relationship: SPOUSE\n",
      "Gender: MALE\n",
      "\n",
      "--- Document ---\n",
      "Name: Sean Anderson\n",
      "Relationship: SPOUSE\n",
      "Gender: MALE\n",
      "\n",
      "--- Document ---\n",
      "Name: Susie Sterling\n",
      "Relationship: CHILD\n",
      "Gender: FEMALE\n",
      "\n",
      "--- Document ---\n",
      "Name: Kevin Abbott\n",
      "Relationship: SPOUSE\n",
      "Gender: MALE\n",
      "\n",
      "--- Document ---\n",
      "Name: Sierra Vance\n",
      "Relationship: CHILD\n",
      "Gender: FEMALE\n"
     ]
    }
   ],
   "source": [
    "def query_index(query, k=3):\n",
    "    # Compute the query's embedding\n",
    "    client = OpenAI()\n",
    "    res = client.embeddings.create(\n",
    "        input=query,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    query_embedding = np.array(res.data[0].embedding, dtype='float32')\n",
    "    # Perform the search in the FAISS index\n",
    "    distances, indices = index.search(np.array([query_embedding]), k)\n",
    "    return indices[0]\n",
    "\n",
    "# Example query\n",
    "query = \"Who are the sons?\"\n",
    "top_indices = query_index(query, k=12)\n",
    "print(\"Top matching document indices:\", top_indices)\n",
    "\n",
    "# Display the top matching documents\n",
    "print(\"\\nTop matching documents:\")\n",
    "for idx in top_indices:\n",
    "    print(\"\\n--- Document ---\")\n",
    "    print(documents[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "107d2d8e-5449-4d68-9567-883e9e7d54c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented prompt for the LLM:\n",
      "\n",
      "You are an HR assistant. Use the following HR documents to answer the question.\n",
      "\n",
      "HR Documents:\n",
      "Name: Benjamin Adams\n",
      "Relationship: CHILD\n",
      "Gender: MALE\n",
      "Name: Mason Vance\n",
      "Relationship: CHILD\n",
      "Gender: MALE\n",
      "Name: Brock Walsh\n",
      "Relationship: CHILD\n",
      "Gender: MALE\n",
      "Name: Mark Vance\n",
      "Relationship: CHILD\n",
      "Gender: MALE\n",
      "Name: Fred Abbott\n",
      "Relationship: CHILD\n",
      "Gender: MALE\n",
      "Name: Matthew Vance\n",
      "Relationship: CHILD\n",
      "Gender: MALE\n",
      "Name: Michael Adams\n",
      "Relationship: SPOUSE\n",
      "Gender: MALE\n",
      "Name: Jonathan Sterling\n",
      "Relationship: SPOUSE\n",
      "Gender: MALE\n",
      "Name: Sean Anderson\n",
      "Relationship: SPOUSE\n",
      "Gender: MALE\n",
      "Name: Susie Sterling\n",
      "Relationship: CHILD\n",
      "Gender: FEMALE\n",
      "Name: Kevin Abbott\n",
      "Relationship: SPOUSE\n",
      "Gender: MALE\n",
      "Name: Sierra Vance\n",
      "Relationship: CHILD\n",
      "Gender: FEMALE\n",
      "\n",
      "Question: Who are the sons?\n",
      "\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the documents corresponding to the top indices\n",
    "retrieved_docs = [documents[i] for i in top_indices]\n",
    "\n",
    "# Construct the prompt\n",
    "prompt = (\n",
    "    \"You are an HR assistant. Use the following HR documents to answer the question.\\n\\n\"\n",
    "    f\"HR Documents:\\n{chr(10).join(retrieved_docs)}\\n\\n\"\n",
    "    f\"Question: {query}\\n\\nAnswer:\"\n",
    ")\n",
    "\n",
    "print(\"Augmented prompt for the LLM:\\n\")\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54722546-d6dc-4d02-88cc-c07457d211b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer:\n",
      " The sons listed in the HR documents are Benjamin Adams, Mason Vance, Brock Walsh, Mark Vance, Fred Abbott, and Matthew Vance.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": prompt}\n",
    "    ],\n",
    ")\n",
    "answer = completion.choices[0].message.content.strip()\n",
    "print(\"Generated Answer:\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "461bb28b-eacc-4a4f-8e77-bf1a793c2138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer:\n",
      " The term \"kings of the company\" typically refers to dominant or leading male figures within a company, but based on the HR documents provided, there is no explicit mention of any specific employee titles or roles that would categorize anyone as such. The documents simply list individuals in relation to others, generally as \"SPOUSE\" or \"CHILD,\" and their genders. Therefore, there is not enough information in the provided documents to accurately determine who might be considered \"kings of the company.\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Who are the kings of the company?\"\n",
    "top_indices = query_index(query, k=12)\n",
    "retrieved_docs = [documents[i] for i in top_indices]\n",
    "prompt = (\n",
    "    \"You are an HR assistant. Use the following HR documents to answer the question.\\n\\n\"\n",
    "    f\"HR Documents:\\n{chr(10).join(retrieved_docs)}\\n\\n\"\n",
    "    f\"Question: {query}\\n\\nAnswer:\"\n",
    ")\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": prompt}\n",
    "    ],\n",
    ")\n",
    "answer = completion.choices[0].message.content.strip()\n",
    "print(\"Generated Answer:\\n\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a22edb-d220-4f73-b23d-3cd61d4b2c2d",
   "metadata": {},
   "source": [
    "# 4. Function Calling\n",
    "\n",
    "Discover how LLMs can be used to trigger and simulate function calls.\n",
    "\n",
    "## Overview\n",
    "- **Definition:** Use LLMs to interpret natural language inputs and execute code functions.\n",
    "- **Applications:**\n",
    "  - Automating routine tasks.\n",
    "  - Integrating user interfaces with backend logic.\n",
    "  - Enhancing code assistants.\n",
    "\n",
    "## How It Works\n",
    "- **Step 1:** Parse the input using an LLM.\n",
    "- **Step 2:** Identify which function to call based on the parsed input.\n",
    "- **Step 3:** Validate parameters and execute the function.\n",
    "- **Step 4:** Return the output.\n",
    "\n",
    "## Example Scenario\n",
    "- **Task:** A user asks, \"Can you schedule a meeting for me tomorrow at 3 PM?\"\n",
    "- **Process:**\n",
    "  1. The LLM parses the input.\n",
    "  2. It maps the request to a `schedule_meeting()` function.\n",
    "  3. Executes the function with appropriate parameters.\n",
    "\n",
    "## Example Code Outline\n",
    "```python\n",
    "def schedule_meeting(time, date, participants):\n",
    "    # Function logic here\n",
    "    return f\"Meeting scheduled on {date} at {time} with {participants}\"\n",
    "\n",
    "# Simulated input from LLM\n",
    "user_input = \"Schedule a meeting for tomorrow at 3 PM with the team.\"\n",
    "parsed_params = {\n",
    "    \"time\": \"3 PM\",\n",
    "    \"date\": \"tomorrow\",\n",
    "    \"participants\": \"the team\"\n",
    "}\n",
    "\n",
    "result = schedule_meeting(**parsed_params)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3109bcc-bfe9-4828-bc9f-facefce683d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
